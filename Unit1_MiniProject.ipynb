{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD-J-6QGzOKQ"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhldolmFzRJ8",
        "outputId": "5c6ef776-ae4e-4a96-8af9-0151594cbcc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"BERT\": \"bert-base-uncased\",\n",
        "    \"RoBERTa\": \"roberta-base\",\n",
        "    \"BART\": \"facebook/bart-base\"\n",
        "}"
      ],
      "metadata": {
        "id": "7FYuFIvmzUb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 1: Text Generation  \n"
      ],
      "metadata": {
        "id": "fkKMp0dR0xT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"The future of Artificial Intelligence is\"\n",
        "\n",
        "for name, model_name in models.items():\n",
        "    print(f\"\\n{name} OUTPUT:\")\n",
        "    try:\n",
        "        generator = pipeline(\"text-generation\", model=model_name)\n",
        "        result = generator(prompt, max_length=30)\n",
        "        print(result[0][\"generated_text\"])\n",
        "    except Exception as e:\n",
        "        print(\"FAILED:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "63f201e7af62451ea819d9edc49ee714",
            "f3701ff0c1a944ddbec7bbfe10aa731e",
            "3f470f90243c4cc0bf7071daaceaa3f6",
            "20c72207c8cd4ad79095b50044993ae6",
            "cdf89295b47d44e6ad8dd8a4996e378d",
            "84a0a10f69b04d47a68a21444548def9",
            "ae416819c5804f158efdd8018c7b1a20",
            "b35f6c0539074270902ab3090f704f49",
            "18e9c42755ba40b1b15afcc94544f282",
            "57d1551387094c048ed07de82044c2d1",
            "dcaa9816f1834155b0b07f978db7ea19",
            "cecd29e0940c474c99db2a5490a5997e",
            "50f3fb81505941fcb680d4f7f5c75519",
            "281f727132ec4d67a6b459ebc1eed9cc",
            "d574e3e682584b07bcc57bca83d88760",
            "42f3862f3ad04512a0ef24d480142ccc",
            "529ea50a76574c0889498966b2744def",
            "c80f7ee5abf24039bf7c2a741e30fae7",
            "d025557207eb4eb9b0d810fa14355334",
            "dc780a4b042c47e4b61471b571514978",
            "ef77668612f34a6eada2840c195da708",
            "7d9947fca2454880a903c31f2e8e902f",
            "e3cb0230833d433c896a22f3836aff4f",
            "48e29023c3e94bff80cbcb93f2fbb554",
            "1c7494b5c47d43d2b04309467476823a",
            "56f54341ffb949ada6f3e3706608af60",
            "eab9bdc389174b79904e8f59315e355d",
            "ba22291f24e04d74925b00db2a3f1dad",
            "9a317e511c0b488bac85eb084cdc53c1",
            "17101585059a4899b8631f26f9864bfc",
            "0fe7bbda37674920a3cdef53a50c307a",
            "0a89580c467246878ffa082708db4dee",
            "83a37e5096be42e295d8d2e2ba94201d",
            "69e860e4fc984a38bdd9dbaa7d64fc9e",
            "254e26c8f91440b89a5a270948878ab0",
            "81b85ba82c804ff3bb7fec5b76bbdbd2",
            "a5dbab210b9c4ac39cf2c777622170ae",
            "4fa60296979c4a2ea14409314ec7bc04",
            "c0ab079040194284a407deb3950ee71f",
            "0ff64a5f575f40b9bd3a8d867a49fdf7",
            "1d8f3875db2b4b04aeaba3493bc5e186",
            "645af700e0ed43f2b40b1d3f60c5cd99",
            "864bd53de44044ae897bf3ced3620eff",
            "a01c727be6c5459fa750c6acc26d4f18",
            "ecade5bdfbf34d73b0f3ad3b177710a1",
            "bd521fbbe2264b01b9655f3acc1aac3c",
            "b40cf59c5bbc4cf681e00be6cd46d9cf",
            "377f7ffcf2f44c078611830ac2a6dd97",
            "a5e9238a2b5347bd9b6d569dfeb69083",
            "bbeab2bddba2417d9111967ef27c086e",
            "8af219e3cfda48b4aea0ba4929392a44",
            "02c8d9d69a5647749320cdfd59016fd8",
            "10b07bfdf33045ce9410a5f942f532b6",
            "8c95425d94b84d23962a641826a0636d",
            "78f37e37ef6a4c33bb37a501b227e501",
            "e3b4b1104a13407783d89096d821ea4e",
            "2dfa8bff10514f5396cb98e82dcfacd7",
            "8ec9b5167c084a61b35c483b7acf8fce",
            "0f876725713747d38116112cdda4e94c",
            "1e9003396f904db4a16fd92623d5d396",
            "a3ff9f5a8d0a4d04a9c684064b003f62",
            "4fd6c69fc6984d79a02d3887f72e5efa",
            "c0df4613705b49e6b8d4e8d413f5e6ca",
            "c4ec97b6716d490a81b412aed8a10592",
            "4c8d7f77acc54529a70a3f40304bb575",
            "836b6a0f0cd742bab35c6be64bd1949a",
            "8295a588c443459bb4680c678dec2ed3",
            "a8fa154214184639a1a5e68c9a6c257e",
            "d5c777c273f14f769398b30490b133ad",
            "29f44606e9794768983783380218ee49",
            "3ca5105d9419456cb758188ceabe6ff7",
            "cc6f46a60864492bb8a27d40cbc42aa8",
            "32ef9851c7044fe0a1f3bbb0799dc7d9",
            "5417132c0b824437872f6106a822ce43",
            "788e7e0092d34aa6bb710a0996a5d2a4",
            "fa1a703bd56a416a9e9f92cb0e98769e",
            "e96f43933a084e1a80390bebf93c7bd0",
            "48a0e535b2a04e3fa55ce9f459fa524f",
            "0919ee637fb74407a2574b6e85baf33f",
            "2cdfbeba68ce4fa084e57056659b4b6b",
            "3f9413aae2db48cfa8448290e23cc47c",
            "8fa7eea0fe764609a79a435981b73762",
            "e5147d6a265f4e1691723d5902ec810f",
            "6189a71278aa4f8ca0caab485a4ed1aa",
            "fe5c148f153749bcbd71042aa4dfc238",
            "38883336ab1e46f48ab3887e09d82524",
            "6e3b9b15fa604c3d9791a772694e7dfb",
            "3d9e311fdddc4bf7ba83bd7cf9f46bba",
            "dc842cb818a043839db1f5cf8b4322da",
            "d9b18b50b46a4a75833825d3ea5d02a2",
            "f7f52ba5b5254c7490cd972c6e4d0c86",
            "4cfcd68db100459191ccad616a9c3d7b",
            "9a7e0128ba32492090419d3b69774dc8",
            "3be139b81184432493ab92b48d56e29e",
            "9e6c6a1da6d248cfac48b235579fce02",
            "ab748071f60744a3b82228f36a1e5cc6",
            "bc7e86b92b00495196a14c639ed4c8c7",
            "6cfaea95eba34ba9a6bd30379a480b39",
            "e0d9163ce7cd44f9949173167805ed54",
            "55e0f96074b843a885b821b86f7fa760",
            "3f7bb6df07da4240b785ff175a816f16",
            "49fd0eaf4830419c80cd5bd2c1382abd",
            "e35022836eac4aac92513047396ffe5d",
            "178078ca80954066a73c920b450cfd83",
            "f7d084a6a3b148a490d520df315c970e",
            "c89e16919d494f469c83a90b86fe82cf",
            "f196932f289248aa9ad187c067942a9b",
            "2540c87b0f0a477193547e6c82e83b92",
            "6f09c803d391496c8df8ebe5daa874cc",
            "914b362071a54240855c13b7501dbff4",
            "2b374920be56436a9d21c876f464eaeb",
            "cd6c32811a27405cac8cffc854a6cc3f",
            "77a127842daa45eeb884e5bab2eaa1c8",
            "26b479bac8a740868c98dd14a5e3fe4b",
            "8bfe1dbef663412c923c5bf430231294",
            "32a5da24a9eb4eb8ac5e98b16a46931f",
            "951eb62545494d47b1371bffd2d9408f",
            "b30031ba9ff64b86ba44c94fe2b4859b",
            "2aaf4810eeb546229f37e890c16ed267",
            "d3bcd73abdf049a190fe74d905603f4c",
            "cdb2396f13ed4d868343b799aa2d15da",
            "b287f47872204253a2bd7dc6480d37a2",
            "824a2ca099ad4794b1441bf48a308dc3",
            "d09d13795b30453d81d333da9ea0bb4b",
            "65250c96471c433ebeee142a18ae8f8d",
            "b0debe32f8344d65999910e2f5621bab",
            "8f8e75d5d28b413d95816c8a1a500606",
            "f30624719b714257bab4e529625ea444",
            "545b43e67be94ed0865a181cf93ceace",
            "78050b94a9e740ee8806612b19930322",
            "cecc509b7c664cc2adf6fe01b6f8b746",
            "934e9aa88fb24c5b96005e56bb112914",
            "c66a81ca44de47a1888cc1b109636bd8",
            "0f771ca62639447c97ab207faea02ba1",
            "ac8d91fa73384fcc90ff3a17a179055a",
            "423f9f00a00b477d8dc25ad8ee0f7c1f",
            "f4d86cd974a34e4d8fbec0458d32b74a",
            "ffa4e6714ca245fb9f214032509bd8d1",
            "08d9cd0b373148f6b004bc0d8f0c4418",
            "06b25893035f42e3afed5a6b8ef1e72c",
            "2c8cf04e34674d8c9eb841a31f448704",
            "b41820c7a9ec408e8a71023cbcbfadae",
            "785aba6af7e54437a663b178d993e8bf",
            "309ee696e442436cbaaf0ec679cf6393",
            "bcf12f603c534ecabc5332c89c1c72a9",
            "0818e2bbbb134432b446ec9641097082",
            "a0c7e595592e4c22a29fc18de7c98bdf",
            "e3c22d7b44ec45df8777efbeafd576e5",
            "d84d7d1498b3411192abc28d92045032",
            "c41b3699813a4fe69546602f8fa4a21a",
            "7a3e0ba2923743f294b4280520601eea",
            "407b16cafe20484db48bfae3809e5f92",
            "0af0f1f699ee4c5fb4c660928535ce01",
            "e5cd8986bc4745efb56b33a739526858",
            "b5d186375a1042319db14e4fcc266d59",
            "10332b2594f94ceebb8a4e3dd9ac5a3a",
            "7e38288a5a14492fa2ea2a3ed0522afe",
            "af3eda65d19e410f8b3784e342e7fde1",
            "e8e7942985bb46d698cd4395187e16c5",
            "891ed73fb5034dfea2bd9087af80b5b6",
            "cd58f97386974d0383c91bfe7a5addfd",
            "bfed8d22de8d4d01ad84e89d4740b5c9",
            "937d1c50b73d4daa846c8b4dcc23b262",
            "6135639b679d4d5491212cdaa3fc46c4",
            "6d57c6b05c6145d5b3f39bce4b528b34",
            "f353661c6c4e4077987c05020d418f88",
            "c3164a15221d48128e4b2da08999df90",
            "79a500e152d347ac96884bc393d79d7a",
            "8213c8eed5614dc28c0b60fe3ffa7487",
            "0df6f5bffe294bd68c5d319f8b05031e",
            "9ff2e19e9403493780ebb2698e722994",
            "8c1a034ea25b479cb831ba15ecd69edd",
            "c7128f0cdd2e445585109a3e15321540",
            "e3c0a0166ed548b2bd952e0a6deb26ae",
            "4bcb499ab200484b8ebb404d40bbe129",
            "6b24acd0253148c1baf4d8825ea1e789"
          ]
        },
        "id": "RAE2Piimzdxw",
        "outputId": "62892d39-47ff-4368-e5ea-b56047e2c697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BERT OUTPUT:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63f201e7af62451ea819d9edc49ee714"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cecd29e0940c474c99db2a5490a5997e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3cb0230833d433c896a22f3836aff4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69e860e4fc984a38bdd9dbaa7d64fc9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecade5bdfbf34d73b0f3ad3b177710a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The future of Artificial Intelligence is................................................................................................................................................................................................................................................................\n",
            "\n",
            "RoBERTa OUTPUT:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3b4b1104a13407783d89096d821ea4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8295a588c443459bb4680c678dec2ed3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48a0e535b2a04e3fa55ce9f459fa524f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc842cb818a043839db1f5cf8b4322da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55e0f96074b843a885b821b86f7fa760"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b374920be56436a9d21c876f464eaeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The future of Artificial Intelligence is\n",
            "\n",
            "BART OUTPUT:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b287f47872204253a2bd7dc6480d37a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c66a81ca44de47a1888cc1b109636bd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BartForCausalLM were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['lm_head.weight', 'model.decoder.embed_tokens.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "309ee696e442436cbaaf0ec679cf6393"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5d186375a1042319db14e4fcc266d59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f353661c6c4e4077987c05020d418f88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The future of Artificial Intelligence isrulesrules owes maps predator predator predatoribe prevalent outfielder prevalent Gulf predator procurement Dual Stephens predator predator programmes Dual Dual neglected groundwork Dualunsignedurionunsigned custody 1200unsigned fingerprints distressed Analysisunsignedunsigned Analysis Gulf Dual Dual Dual Ridunsigned 1939 1939itable fingerprints circumvent fingerprints Gulf Gulf Athenmaximum Dual Dualoxin Analysis outfielder Dual Ridurionurion Rid RidunsignedmaximumKOmaximum Dual Rid463adositableitable Ridunsigneditable Lesitable sprayed Elliotitableunsigneditable circumvent datasetitable Analysisitable Durham Dual Rid RidKO Les DualitablebitsKOitableunsigned Analysis Analysisunsigned RideyedunsignedunsignedsemblysemblysemblyoxinKOkar Rid dataset Martial Martialendaleitable Gulfkar outfielder Rid Dualitable Martial Martial Dual Dual dataset custodyWT Rid Riditable custodyWTversitable Justice Elliotarationsunsigneditable Ridankeitable custody custodyitablesponsoredrivedrived Martialitable intuitionoxin conditionedrived Elliotsemblysembly RESoxinvers Elliot enormously custodyverssemblysembly\u30b4 emphaticallysemblyleasingoxin outfielderWT RES RESiaturessemblysembly pokeroxin datasetsembly enormously Elliot Philipp intuition RES conditionedrived RES RESrivedrived Elliotarations dataset Justicevers952 Elliotsembly Justice Elliot Elliot Philipp consequence RES lovelyarationssembly Elliotleasing intuition Elliot Elliot ElliotOpsuanaversWT dataset Elliot Elliot intuition Elliot rotsemblyrestlingversOpsarations residential Elliot Elliot RES SU cloningvers Rid Elliot residential RES Elliot RESvers Elliot Elliotsemblyleasingsembly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 2: Masked Language Modeling  \n",
        "**Sentence:** \"The goal of Generative AI is to [MASK] new content.\"  \n",
        "\n"
      ],
      "metadata": {
        "id": "b__5tXf20faj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "models = {\n",
        "    \"BERT\": \"bert-base-uncased\",\n",
        "    \"RoBERTa\": \"roberta-base\",\n",
        "    \"BART\": \"facebook/bart-base\"\n",
        "}\n",
        "\n",
        "texts = {\n",
        "    \"BERT\": \"The goal of Generative AI is to [MASK] new content.\",\n",
        "    \"RoBERTa\": \"The goal of Generative AI is to <mask> new content.\",\n",
        "    \"BART\": \"The goal of Generative AI is to <mask> new content.\"\n",
        "}\n",
        "\n",
        "for name, model_name in models.items():\n",
        "    print(f\"\\n{name} OUTPUT:\")\n",
        "    try:\n",
        "        masker = pipeline(\"fill-mask\", model=model_name)\n",
        "        results = masker(texts[name])\n",
        "        for r in results[:3]:\n",
        "            print(r[\"token_str\"], \"-\", r[\"score\"])\n",
        "    except Exception as e:\n",
        "        print(\"FAILED:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6f40194abbce43ec917ab717827434c2",
            "07f4348b64e245569ebd5d06fe08cb09",
            "a32e40c3bfcc497d8a774e2b7029d24c",
            "e6ccbaabb0a84b3ebbd46b1fa56d0017",
            "83b8cc17d0c948d4b5b10c75739033b1",
            "65270e6e7b6c4af38ed1b82864b227d6",
            "6299013ed9814194a0b7adb0199d51b2",
            "b26d924337754daa9f60db2f2331ceac",
            "119dcca7424c4699bace00a10e5d5b48",
            "dd5415c81a7c4614841f5b0bdbe3e653",
            "c685804dc055464c814ea6403963006c",
            "faaf29a385724d209a64e75efc5a4237",
            "e4de27a42c5142deb0a0072a00576a0b",
            "cb7a1be532e041f9989b3cd47f9c4f6c",
            "4df8e5b1dc08460989c2a7aa019e15ef",
            "16b475f58697498fae00abd7c1d831d5",
            "e166a658b6664daaa97aa432a552f7e8",
            "2060bc99f91a4fe1b50b92adb2b8e9ba",
            "24388ef8e2344852872d04fbf60bbf0c",
            "d23aa75a90f24040b6a27e706fff03b2",
            "b0a87dde1a9240eaad965a6f7106bf21",
            "a8b28e0f22024c3dbd24b14718970e39",
            "3d4b6663cbce47b78e65ebccae94996f",
            "89c9912c47fd4ac19716158fcd0ab0e1",
            "54d1eb64d73e4a99bcff731c910d5323",
            "7470a18a8a2949669b29ce3294f90235",
            "0b66c95442a2450a9af10c1dab621feb",
            "d24beb78a1ce4351b854294fc562e279",
            "3c6f4e4936914c958d2042bf8d99322c",
            "cdf35221e67e4fd1bb23c0941125feee",
            "adc2172c234f4991924b8ddbfb68840b",
            "1d88e446217f4eed83266ce5a5611e56",
            "6ce7203de1f24528b686ff84c7eba92f",
            "f06ad3ec89164da9901c0fe295c3f5a0",
            "6b8a6805450f4bbf9ffe78f02d2f07a0",
            "7d96a20096f54d29a29eec275aa1643a",
            "b11a90a942fb46e8a12fef2eefe6d349",
            "f5e44edfd66343e7a23af993c3b67a92",
            "aa1ff65b1c1a4215a670b2a7bc9690d0",
            "3c3f0a17a5a3424a8fef254bd7fb8824",
            "47118095a7d3496abc500fb55fac5e7c",
            "e9a8781bf368448d8d97f4824bb5d32e",
            "47c76bb9fbb44d9f88f2c3ce3f9d9e94",
            "94c00657d1094fb0a8f3d5dcd84121f6",
            "7722546e94f14a7ba528a9a4e370070a",
            "4eecdeb2fa9644868a97c76fb7a309f3",
            "c0d282daa4d142a89387d504da4cc8e3",
            "8b5cda79c05447f99031676004d696de",
            "b0964d7bf7664c239715e16ed4bc16da",
            "97c5f47943e04ef3b5c400d3cdde0fd4",
            "64b6d1d63af744a8af5d95c85155fd16",
            "75d37789f3c54deba5168c01e8c8c611",
            "4afe4d4de18f42d38f431e86f1a51aba",
            "81c3c01951454b69866b91fc6705dd19",
            "5bcc575024744ec1a722a270b4be1184",
            "9ab638b6951943b1be72cf0330a03c0d",
            "13727d21ea594ebba5fe3cc4e2e07ec4",
            "f6df904419364717a0c974350c70e62d",
            "c40022654d424df885fe66851a4222e0",
            "a169e4f6f7da4c79a54e0d4f69959bb2",
            "bd998df393b1471caab33e38be15be4b",
            "574db087d0a645418f817397825b27fa",
            "95f16bc46a1d4094bbc47294568a997b",
            "10a6053690654865a232dc311eed372e",
            "1618f5e7ce454cf9b2f2789330850e84",
            "71c0fa0d06094c1ea4532fdbcdf4553a",
            "e35c3660cb9b4176808bb2dc6e37fbed",
            "17a595595b724bd39c7ab71a894da099",
            "2c7b0c77830247bf87b05ba60e19bfe0",
            "ace17e524b834204a1fa181eae7003dc",
            "0d195bc173a14820bb30dd30a7c2b9d7",
            "6e76aba40cce42de9f16b21ad845f418",
            "c1b8db6f4dc148b3aff2f05be67c784f",
            "c392207cc7e540b99a9c44c8390684e4",
            "9c7e2229dc764c4b98b6f8be8af4eddc",
            "1e3bdf63ffc4449d97868c6868a10a35",
            "58b7cc437c424ec3ad3f068c41045c39",
            "39e6a35edf974673b913b25cb759b486",
            "3eeddc6453f147a5a7dc5d1a2d99b4df",
            "282a7bdc9ca941d6856acd3878cdb984",
            "6f113a8416a44cea9da53d6ac2bf7d3c",
            "1ec7de482ded4fca9e5061aefb94b962",
            "1b15b2dcadd34849b4caea988718d61d",
            "f7f958106d814798a5c414035335b2e9",
            "695d04a9a92941069c261b4abec29cb8",
            "a2d86b61b381455ba1debbc94ca70c69",
            "24c8e9d16e794dd591d88a250f1d4e56",
            "76cd9af32e494a4881c3365bcd3a4d10",
            "863af38465f2494e9d5b2e7816f144c1",
            "5b11f24868d5466989d75b6226675f8f",
            "55d2c2680cf1478b8831184461a5f295",
            "852a31a4cbff4b239b81a029ffca7342",
            "dde33b2851ab4739b473565d7378a7af",
            "05b991226cde44d68e8f6f2cfd0b679b",
            "438cd584698f4d9d9894fa34018d879c",
            "c45f138892f44819ad8e61bfac3482a7",
            "2b33a61f5e1542109920e30594719a90",
            "4d0fd7a3700040f895971cc3509e73ad",
            "e815c79d41a141b082f93c971e31f145",
            "5f955ca0262843daaf61f4b1732fd5f3",
            "9223ae4e830742edaf1887eb80747049",
            "1aa073dd7d144a0386abfb60b93ec46c",
            "a049bcb1b1964cd4b8819ff349bc1fe1",
            "c001e9f455f84e84863997550059447e",
            "5a14dae1d85747ab8ad3804350f3143d",
            "8323753dc81c47618618be1cc733d6fc",
            "aa118136d2124d43948f97e04b53ff2f",
            "acb4949b63ab4677bd007878ddb05c2f",
            "eb29b85b9bc34139a1a615c748d0820f",
            "d3538c4e1b8d46c585c00cd8081cf1e2",
            "dbf9f008ea13402cba0c06d4b697a66c",
            "374a841cfd4b4aca9797e7b6c4945c14",
            "b12917f99e53454bb89625fa9f2f8525",
            "ae35959fbe5045e09e524c5343042171",
            "a74eec39ea9c4c56920513d93a20b754",
            "5db5c5a469c64e00b533a35d17993e3a",
            "070706338e32483bb720c205b37abc04",
            "a44ae83ca4b74f7886bf278e7bb4616c",
            "e8002bbf77c7456ca5c36624d7e01274",
            "2301d05531af426d89caf0012cb74399",
            "6c5ff0afe07441a6a00a67e374c97129",
            "d0d861e8d122428a92202b5c0a700f87",
            "e144f231a83744e0bd34b0606a5c5c8c",
            "a92b2babc48e4584814cd37c049d81aa",
            "3526ab94913643979631375f8576424a",
            "c4557af7b59f4416bcdaa4e2e91d4b93",
            "018d0f45feef4261978de479164dab70",
            "f3374c07fa2e4d13afd3dd7a70775953",
            "4677170901f545a09bb36fdce19ebf49",
            "7fd2f3f0800141fdb10c06a306326b4c",
            "6f7e723462b74b18bdaeb97ce8aa7ef3",
            "85f127f7323f480d86eafbecd9e3cbe0",
            "9f308c7de9724698973e8f78ed36cdee",
            "e4a67623f2504d5f85d6433343821d47",
            "8ec601e3348743d8ab84fa613902a00f",
            "cef45cd7381c4d7a900d99c8b67085a2",
            "6dc9ffb4107b48ca953afb49b6c8a345",
            "9928ea3bb1dd47b78b9904347db38abd",
            "85bdd047d1844c8196878d462c6a7431",
            "02e99d9961c84a3492c811892686f233",
            "a66d7927ad7d468a9ebfc1ac3aeaa7ee",
            "ca61556bded94962bd3afd9c6703c1b0",
            "4c6cc93bda9b481b8d5a8ee4a44120d5",
            "1b3b7c96ab4d434eba90293e5838baa7",
            "b3178e4f37b04551adc7dba35b3ef723",
            "ce861279f9cf41788354a59292702ce6",
            "08e9822bc35e48cb80e9d916b55effed",
            "ae56d200e2a74702b2dfae432829a0bb",
            "35b1440ee12c46c3827970709815e375",
            "d812fd5710264cd8809bf0973a461628",
            "a91a1f6a897845f69048672efaaf4401",
            "23cc413b62db4be88294facacd0f8310",
            "096a55fabc3f4f3d987100ea5d59274a",
            "78c21435b5854d82a978a2a037585888",
            "8e999f968f5048f78238edfe182ccc32",
            "596390c8198a4e2fb2acf5d626045db0",
            "7e9652ff164c4f818cab159471b138fb",
            "c099c02de9734403b0e4049406408df3",
            "b4e9d14f85b74e83be9da4ece6512fc4",
            "52917732a41b41a7a63b29ff55b2e550",
            "8617bfb36b014fc69847d61f20e36b67",
            "850e99c20c884b4e874018f2a38ea6c6",
            "a9aadcb9a88947c194de7d74323e7d31",
            "d6d5e491dbc44be7903d63570ae8a6bb",
            "99894d1553fc4a2c9f0b7e56f4c7c636",
            "275cafe2843b4df5830b2894f25425e1",
            "a8feb835df0f4b108099eb90ee53c4de",
            "4b1df010795a450483a2e9a81ec13899",
            "27246938f0254200b6baa909ee68790e",
            "c06e9129795543e0851730bac9d89ca1",
            "4a016bbfbacd42549e30d7e24a9452dc",
            "a22bb746525149928b14b723a27065df",
            "905e232093014e72ab5925fbfd2706bf",
            "34e74fe256634317bd6d0985afe5120c",
            "41908f5344d24bd59b76b0bdb87df3cb",
            "2066b6fc694940f2981fe96962d8833e"
          ]
        },
        "id": "PXvbNg4rzhgv",
        "outputId": "f67968bd-29ba-48ac-d921-b1d896b70d8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BERT OUTPUT:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f40194abbce43ec917ab717827434c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faaf29a385724d209a64e75efc5a4237"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d4b6663cbce47b78e65ebccae94996f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f06ad3ec89164da9901c0fe295c3f5a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7722546e94f14a7ba528a9a4e370070a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create - 0.5396932363510132\n",
            "generate - 0.15575720369815826\n",
            "produce - 0.05405500903725624\n",
            "\n",
            "RoBERTa OUTPUT:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ab638b6951943b1be72cf0330a03c0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e35c3660cb9b4176808bb2dc6e37fbed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39e6a35edf974673b913b25cb759b486"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "863af38465f2494e9d5b2e7816f144c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f955ca0262843daaf61f4b1732fd5f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbf9f008ea13402cba0c06d4b697a66c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " generate - 0.3711312413215637\n",
            " create - 0.3677145540714264\n",
            " discover - 0.08351420611143112\n",
            "\n",
            "BART OUTPUT:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0d861e8d122428a92202b5c0a700f87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f308c7de9724698973e8f78ed36cdee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b3b7c96ab4d434eba90293e5838baa7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e999f968f5048f78238edfe182ccc32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "275cafe2843b4df5830b2894f25425e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " create - 0.07461541891098022\n",
            " help - 0.06571870297193527\n",
            " provide - 0.060880109667778015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 3: Question Answering  \n",
        "**Context:** Generative AI poses significant risks such as hallucinations, bias, and deepfakes.  \n",
        "**Question:** What are the risks?  \n",
        "\n"
      ],
      "metadata": {
        "id": "q97UU6pI0c29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"Generative AI poses significant risks such as hallucinations, bias, and deepfakes.\"\n",
        "question = \"What are the risks?\"\n",
        "\n",
        "for name, model_name in models.items():\n",
        "    print(f\"\\n{name} OUTPUT:\")\n",
        "    try:\n",
        "        qa = pipeline(\"question-answering\", model=model_name)\n",
        "        result = qa(question=question, context=context)\n",
        "        print(result)\n",
        "    except Exception as e:\n",
        "        print(\"FAILED:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPt4qAsOzx34",
        "outputId": "ca8a4a8a-663a-45f7-d46f-fafcd3cd40f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BERT OUTPUT:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.004214718472212553, 'start': 0, 'end': 37, 'answer': 'Generative AI poses significant risks'}\n",
            "\n",
            "RoBERTa OUTPUT:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Some weights of BartForQuestionAnswering were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.01231402950361371, 'start': 43, 'end': 81, 'answer': 'as hallucinations, bias, and deepfakes'}\n",
            "\n",
            "BART OUTPUT:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.005052782595157623, 'start': 43, 'end': 45, 'answer': 'as'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observation Table\n",
        "\n",
        "| Task | Model | Classification (Success/Failure) | Observation (What actually happened?) | Why did this happen? (Architectural Reason) |\n",
        "|------|--------|--------------------------------|--------------------------------------|---------------------------------------------|\n",
        "| Generation | BERT | Failure | Generated only symbols | BERT is encoder-only, not trained for next-token generation |\n",
        "| Generation | RoBERTa | Failure | Did not generate anything | RoBERTa is also encoder-only |\n",
        "| Generation | BART | Success | Generated coherent continuation | BART is encoder-decoder and trained for seq2seq generation |\n",
        "|Fill-Mask | BERT | Success | Predicted \u201ccreate\u201d, \u201cgenerate\u201d, \u201cproduce\u201d with high confidence | BERT is trained using Masked Language Modeling (MLM) |\n",
        "| Fill-Mask | RoBERTa | Success | Predicted \u201cgenerate\u201d, \u201ccreate\u201d, \u201cdiscover\u201d | RoBERTa is trained with MLM but uses different tokenizer and training improvements |\n",
        "| Fill-Mask | BART | Partial | Predicted \u201ccreate\u201d, \u201chelp\u201d, \u201cprovide\u201d with lower confidence | BART is not primarily trained for MLM; it is optimized for sequence-to-sequence tasks |\n",
        "| QA | BERT | Partial | Returned: \"Generative AI poses significant risks\" with very low confidence | QA head randomly initialized; model not fine-tuned for QA |\n",
        "| QA | RoBERTa | Partial | Returned partial answer: \"as hallucinations, bias, and deepfakes\" | QA head not trained; base model not optimized for extractive QA |\n",
        "| QA | BART | Failure | Returned incorrect short span: \"as\" | BART is generative and not designed for extractive QA |\n"
      ],
      "metadata": {
        "id": "EgF2Roq50Eu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "This benchmark shows that **model architecture strongly determines task performance**.  \n",
        "- Encoder-only models (BERT, RoBERTa) excel at understanding tasks like masked word prediction.  \n",
        "- Encoder-decoder models (BART) are designed for generation tasks and perform best in text generation.  \n",
        "- Base models perform poorly on QA because they require fine-tuning on datasets like SQuAD.\n",
        "\n",
        "This experiment demonstrates why choosing the correct architecture is critical in Generative AI systems.\n"
      ],
      "metadata": {
        "id": "Sv3mZb580Z4g"
      }
    }
  ]
}